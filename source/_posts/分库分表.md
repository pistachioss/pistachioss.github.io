---
title: Sharding分库分表实践
date: 2024-09-02
categories: ShardingSphere
tags: wiki
toc: true
description: "Sharding分库分表实践、主从读取"

---

好的，我们来详细讲解如何在 Spring Boot 项目中实战分库分表与读写分离。我们将选用业界广泛使用的 **ShardingSphere**（其 JDBC 驱动形式，即原 Sharding-JDBC）作为核心框架，因为它与 Spring Boot 集成良好，功能强大且社区活跃。

## **目标场景:**

1.  **分库 (Vertical/Horizontal Sharding - Database Level):** 将原来的单个 `order` 库拆分成两个物理库：`ds_0` 和 `ds_1`。`t_order` 和 `t_order_detail` 两张表的数据将根据某个规则（例如 `order_id` 或 `user_id`）分散到这两个库中。注意：这里不是垂直分库（一个库放 order，一个库放 detail），而是水平分库，每个库都有 `t_order` 和 `t_order_detail` 的一部分数据。
2.  **分表 (Horizontal Sharding - Table Level):** 在每个物理库 (`ds_0`, `ds_1`) 内部，`t_order` 表再分成两张物理表 `t_order_0`, `t_order_1`；`t_order_detail` 表也分成 `t_order_detail_0`, `t_order_detail_1`。分表规则通常也与 `order_id` 相关。
3.  **读写分离 (Read/Write Splitting):** 为每个分片后的物理库（`ds_0`, `ds_1`）配置主从数据库。写入操作（INSERT, UPDATE, DELETE）路由到主库，读取操作（SELECT）路由到从库，以提高读取性能和可用性。
4.  **绑定表 (Binding Tables):** `t_order` 和 `t_order_detail` 是典型的关联表，它们应该始终位于同一个数据库分片和对应的表分片中（例如，`order_id` 为 100 的订单及其详情，如果 `t_order` 路由到 `ds_0.t_order_0`，那么 `t_order_detail` 也应该路由到 `ds_0.t_order_detail_0`）。ShardingSphere 支持配置绑定表来保证这一点。
5.  **分布式主键:** 使用 ShardingSphere 提供的 Snowflake 算法自动生成全局唯一的 `order_id`。

## 技术选型:**

*   **核心框架:** Apache ShardingSphere (via `shardingsphere-jdbc-core-spring-boot-starter`)
*   **数据库:** MySQL (演示需要至少 4 个实例：2 主 2 从)
*   **持久层:** MyBatis (使用 `mybatis-spring-boot-starter`，JPA 也可以类似配置)
*   **构建工具:** Maven
*   **开发环境:** Spring Boot (e.g., 2.7.x or 3.x), Java 8+

---

## 步骤详解:**

### 第一步：环境准备与数据库设置**

1.  **安装 MySQL:** 确保你有可用的 MySQL 服务。为了模拟读写分离和分库，你需要创建 4 个数据库实例（或在同一实例中创建 4 个 database）。我们假设：
    *   `ds_0_master`: 主库 0 (写入 + 可能的读取)
    *   `ds_0_slave`: 从库 0 (只读)
    *   `ds_1_master`: 主库 1 (写入 + 可能的读取)
    *   `ds_1_slave`: 从库 1 (只读)

    *注意:* 实际生产环境中，你需要配置 MySQL 的主从复制，确保 `ds_0_slave` 复制 `ds_0_master`，`ds_1_slave` 复制 `ds_1_master`。本示例代码不包含 MySQL 复制的配置，仅演示 ShardingSphere 如何连接和路由。

2.  **创建数据库和表:** 在对应的 MySQL 实例上执行以下 SQL。

    ```sql
    -- 在 ds_0_master 和 ds_0_slave 上执行 (假设已创建好数据库 ds_0)
    -- USE ds_0; -- 如果需要指定数据库
    
    CREATE TABLE `t_order_0` (
      `order_id` bigint NOT NULL,
      `user_id` int NOT NULL,
      `order_no` varchar(100) DEFAULT NULL,
      `amount` decimal(10,2) DEFAULT NULL,
      `create_time` datetime DEFAULT CURRENT_TIMESTAMP,
      PRIMARY KEY (`order_id`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    
    CREATE TABLE `t_order_1` (
      `order_id` bigint NOT NULL,
      `user_id` int NOT NULL,
      `order_no` varchar(100) DEFAULT NULL,
      `amount` decimal(10,2) DEFAULT NULL,
      `create_time` datetime DEFAULT CURRENT_TIMESTAMP,
      PRIMARY KEY (`order_id`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    
    CREATE TABLE `t_order_detail_0` (
      `detail_id` bigint NOT NULL AUTO_INCREMENT, -- 详情ID通常用自增，或也可用分布式ID
      `order_id` bigint NOT NULL,
      `item_name` varchar(255) DEFAULT NULL,
      `quantity` int DEFAULT NULL,
      PRIMARY KEY (`detail_id`),
      KEY `idx_order_id` (`order_id`) -- 必须有 order_id 索引，用于关联查询和路由
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    
    CREATE TABLE `t_order_detail_1` (
      `detail_id` bigint NOT NULL AUTO_INCREMENT,
      `order_id` bigint NOT NULL,
      `item_name` varchar(255) DEFAULT NULL,
      `quantity` int DEFAULT NULL,
      PRIMARY KEY (`detail_id`),
      KEY `idx_order_id` (`order_id`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    
    -- 在 ds_1_master 和 ds_1_slave 上执行 (假设已创建好数据库 ds_1)
    -- USE ds_1; -- 如果需要指定数据库
    
    -- 重复上面的 CREATE TABLE 语句，创建 ds_1 库中的 t_order_0, t_order_1, t_order_detail_0, t_order_detail_1
    CREATE TABLE `t_order_0` ( ... );
    CREATE TABLE `t_order_1` ( ... );
    CREATE TABLE `t_order_detail_0` ( ... );
    CREATE TABLE `t_order_detail_1` ( ... );
    ```

## 第二步：创建 Spring Boot 项目并添加依赖**

1.  使用 Spring Initializr (start.spring.io) 或 IDE 创建一个新的 Spring Boot 项目。
2.  选择以下依赖：
    *   Spring Web (用于创建测试 Controller)
    *   Lombok (简化代码)
    *   MySQL Driver
    *   MyBatis Framework (或 Spring Data JPA)
    *   **Apache ShardingSphere JDBC Core**

3.  `pom.xml` (关键依赖):

    ```xml
    <dependencies>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
        </dependency>
        <dependency>
            <groupId>org.mybatis.spring.boot</groupId>
            <artifactId>mybatis-spring-boot-starter</artifactId>
            <version>3.0.2</version> <!-- Use appropriate version -->
        </dependency>
        <dependency>
            <groupId>org.apache.shardingsphere</groupId>
            <artifactId>shardingsphere-jdbc-core-spring-boot-starter</artifactId>
            <version>5.4.0</version> <!-- Use latest stable ShardingSphere 5.x version -->
        </dependency>
        <dependency>
            <groupId>mysql</groupId>
            <artifactId>mysql-connector-java</artifactId>
            <scope>runtime</scope>
             <!-- Use 8.x connector if using MySQL 8+ -->
            <version>8.0.33</version>
        </dependency>
        <dependency>
            <groupId>org.projectlombok</groupId>
            <artifactId>lombok</artifactId>
            <optional>true</optional>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-test</artifactId>
            <scope>test</scope>
        </dependency>
    </dependencies>
    ```

## 第三步：配置 ShardingSphere (`application.yml`)**

这是核心配置，定义了数据源、分片规则、读写分离规则等。

```yaml
spring:
  shardingsphere:
    # 1. 定义真实数据源 (Actual Data Sources)
    datasource:
      names: ds_0_master, ds_0_slave, ds_1_master, ds_1_slave # 列出所有物理数据源bean名称
      # 配置 ds_0_master
      ds_0_master:
        type: com.zaxxer.hikari.HikariDataSource # 使用 HikariCP 连接池
        driver-class-name: com.mysql.cj.jdbc.Driver
        jdbc-url: jdbc:mysql://localhost:3306/ds_0?useSSL=false&serverTimezone=UTC&characterEncoding=UTF-8
        username: root
        password: your_password_ds_0_master
      # 配置 ds_0_slave
      ds_0_slave:
        type: com.zaxxer.hikari.HikariDataSource
        driver-class-name: com.mysql.cj.jdbc.Driver
        jdbc-url: jdbc:mysql://localhost:3307/ds_0?useSSL=false&serverTimezone=UTC&characterEncoding=UTF-8 # 假设从库在3307端口
        username: root
        password: your_password_ds_0_slave
      # 配置 ds_1_master
      ds_1_master:
        type: com.zaxxer.hikari.HikariDataSource
        driver-class-name: com.mysql.cj.jdbc.Driver
        jdbc-url: jdbc:mysql://localhost:3308/ds_1?useSSL=false&serverTimezone=UTC&characterEncoding=UTF-8 # 假设主库1在3308端口
        username: root
        password: your_password_ds_1_master
      # 配置 ds_1_slave
      ds_1_slave:
        type: com.zaxxer.hikari.HikariDataSource
        driver-class-name: com.mysql.cj.jdbc.Driver
        jdbc-url: jdbc:mysql://localhost:3309/ds_1?useSSL=false&serverTimezone=UTC&characterEncoding=UTF-8 # 假设从库1在3309端口
        username: root
        password: your_password_ds_1_slave

    # 2. 定义规则 (Rules)
    rules:
      # 2.1 读写分离规则 (Read/Write Splitting Rules)
      readwrite-splitting:
        data-sources:
          # 定义逻辑读写分离数据源组 rw_ds_0
          rw_ds_0:
            write-data-source-name: ds_0_master # 主库
            read-data-source-names: # 从库列表
              - ds_0_slave
            # load-balancer-name: round_robin # 可选：指定从库负载均衡算法 (默认轮询)
          # 定义逻辑读写分离数据源组 rw_ds_1
          rw_ds_1:
            write-data-source-name: ds_1_master
            read-data-source-names:
              - ds_1_slave
            # load-balancer-name: random # 可选：随机算法
        # 可选: 定义负载均衡算法
        # load-balancers:
        #   round_robin:
        #     type: ROUND_ROBIN
        #   random:
        #     type: RANDOM

      # 2.2 分片规则 (Sharding Rules)
      sharding:
        # 绑定表：确保 t_order 和 t_order_detail 的分片逻辑一致
        binding-tables:
          - t_order, t_order_detail

        # 默认分片策略 (可选, 如果所有表策略相同)
        # default-database-strategy:
        # default-table-strategy:

        # 定义逻辑表及其分片规则
        tables:
          # t_order 表的规则
          t_order:
            # 数据节点：逻辑表 t_order 对应哪些物理库/表
            # 使用之前定义的读写分离逻辑数据源名 rw_ds_0, rw_ds_1
            # 格式: <逻辑数据源名/真实数据源名>.<逻辑表名/真实表名>
            # ${0..1} 表示 0 到 1 的范围
            actual-data-nodes: rw_ds_${0..1}.t_order_${0..1}
            # 分库策略 (Database Sharding Strategy)
            database-strategy:
              standard: # 标准分片策略
                sharding-column: order_id # 分库的键
                sharding-algorithm-name: db_mod_sharding_alg # 使用下面定义的算法
            # 分表策略 (Table Sharding Strategy)
            table-strategy:
              standard:
                sharding-column: order_id # 分表的键 (与分库键相同，保证绑定表有效)
                sharding-algorithm-name: table_mod_sharding_alg # 使用下面定义的算法
            # 主键生成策略 (Key Generation Strategy)
            key-generate-strategy:
              column: order_id # 指定 order_id 列由 ShardingSphere 生成
              key-generator-name: snowflake_key_gen # 使用下面定义的 Snowflake 算法

          # t_order_detail 表的规则
          t_order_detail:
            # 数据节点
            actual-data-nodes: rw_ds_${0..1}.t_order_detail_${0..1}
            # 分库策略 (与 t_order 相同，因为是绑定表)
            database-strategy:
              standard:
                sharding-column: order_id # 必须用 order_id 来保证和 t_order 路由到同一库
                sharding-algorithm-name: db_mod_sharding_alg
            # 分表策略 (与 t_order 相同，因为是绑定表)
            table-strategy:
              standard:
                sharding-column: order_id # 必须用 order_id 来保证和 t_order 路由到同一表后缀
                sharding-algorithm-name: table_mod_sharding_alg
            # detail_id 可以使用数据库自增，或者也配置 ShardingSphere 的分布式 ID (如 UUID)
            # key-generate-strategy:
            #   column: detail_id
            #   key-generator-name: uuid_key_gen # 假设定义一个 uuid generator

        # 定义分片算法 (Sharding Algorithms)
        sharding-algorithms:
          # 数据库分片算法：根据 order_id % 2 决定库 (0 -> rw_ds_0, 1 -> rw_ds_1)
          db_mod_sharding_alg:
            type: MOD # 取模算法
            props:
              sharding-count: 2 # 分片数量 (库的数量)
          # 表分片算法：根据 order_id % 2 决定表后缀 (0 -> _0, 1 -> _1)
          table_mod_sharding_alg:
            type: MOD
            props:
              sharding-count: 2 # 分片数量 (每个库内表的数量)

        # 定义主键生成器 (Key Generators)
        key-generators:
          snowflake_key_gen:
            type: SNOWFLAKE # 使用 Snowflake 算法
            # props: # 可选：配置 worker-id 等，通常自动生成即可
            #   worker-id: 1
          # uuid_key_gen:
          #   type: UUID

    # 3. 其他属性 (Props)
    props:
      sql-show: true # 打印 ShardingSphere 解析和路由后的真实 SQL，便于调试

# MyBatis 配置 (如果使用 MyBatis)
mybatis:
  mapper-locations: classpath:mapper/*.xml # Mapper XML 文件位置
  # type-aliases-package: com.example.shardingdemo.entity # 实体类别名包
  configuration:
    map-underscore-to-camel-case: true # 开启驼峰命名转换

# 确保日志级别允许查看 ShardingSphere 的 SQL (可选，但推荐调试时使用)
logging:
  level:
    org.apache.shardingsphere: info # 可以设为 DEBUG 获取更详细信息
    # com.example.shardingdemo.mapper: debug # 打印你的 Mapper 接口执行的 SQL
```

## 第四步：编写 Java 代码**

1.  **实体类 (Entity)**

    ```java
    package com.example.shardingdemo.entity;

    import lombok.Data;
    import java.math.BigDecimal;
    import java.time.LocalDateTime;

    @Data
    public class Order {
        private Long orderId; // 使用 Long 对应 bigint，由 ShardingSphere 生成
        private Integer userId;
        private String orderNo;
        private BigDecimal amount;
        private LocalDateTime createTime;
    }

    @Data
    public class OrderDetail {
        private Long detailId; // 可以是数据库自增，也可以是 ShardingSphere 生成
        private Long orderId; // 分片键，必须存在
        private String itemName;
        private Integer quantity;
    }
    ```

2.  **Mapper 接口 (Mapper Interface)**

    ```java
    package com.example.shardingdemo.mapper;

    import com.example.shardingdemo.entity.Order;
    import com.example.shardingdemo.entity.OrderDetail;
    import org.apache.ibatis.annotations.Insert;
    import org.apache.ibatis.annotations.Mapper;
    import org.apache.ibatis.annotations.Options;
    import org.apache.ibatis.annotations.Param;
    import org.apache.ibatis.annotations.Select;
    import java.util.List;

    @Mapper
    public interface OrderMapper {

        // 插入 Order，注意 orderId 不需要手动设置，由 ShardingSphere 注入
        @Insert("INSERT INTO t_order (user_id, order_no, amount) VALUES (#{userId}, #{orderNo}, #{amount})")
        @Options(useGeneratedKeys = true, keyProperty = "orderId", keyColumn = "order_id") // 让 MyBatis 返回 ShardingSphere 生成的 ID
        int insertOrder(Order order);

        @Select("SELECT * FROM t_order WHERE order_id = #{orderId}")
        Order selectOrderById(@Param("orderId") Long orderId);

        // 查询某个用户的所有订单 (会查询所有库表，可能需要优化或避免)
        @Select("SELECT * FROM t_order WHERE user_id = #{userId}")
        List<Order> selectOrdersByUserId(@Param("userId") Integer userId);

        // 范围查询 (会查询所有库表)
        @Select("SELECT * FROM t_order WHERE order_id BETWEEN #{startId} AND #{endId}")
        List<Order> selectOrdersByIdRange(@Param("startId") Long startId, @Param("endId") Long endId);
    }

    @Mapper
    public interface OrderDetailMapper {

        // 插入 OrderDetail，orderId 是关联的外键和分片键
        // 如果 detailId 是自增，可以不返回；如果是 ShardingSphere 生成，类似 Order 配置 @Options
        @Insert("INSERT INTO t_order_detail (order_id, item_name, quantity) VALUES (#{orderId}, #{itemName}, #{quantity})")
        @Options(useGeneratedKeys = true, keyProperty = "detailId", keyColumn = "detail_id") // 假设 detailId 是自增
        int insertDetail(OrderDetail detail);

        @Select("SELECT * FROM t_order_detail WHERE order_id = #{orderId}")
        List<OrderDetail> selectDetailsByOrderId(@Param("orderId") Long orderId);

        @Select("SELECT * FROM t_order_detail WHERE detail_id = #{detailId} AND order_id = #{orderId}")
        OrderDetail selectDetailByIdAndOrderId(@Param("detailId") Long detailId, @Param("orderId") Long orderId);
    }
    ```
    *注意:*
    *   `t_order` 的 `order_id` 由 ShardingSphere 的 Snowflake 算法生成，插入时不需要提供，但需要通过 `@Options` 让 MyBatis 能获取到生成的值。
    *   `t_order_detail` 的插入需要提供 `order_id`，这个 `order_id` 就是刚插入 `t_order` 时获取到的 `order_id`。ShardingSphere 会根据这个 `order_id` 将详情数据路由到与主订单相同的库和表中。
    *   查询时，如果 WHERE 条件中包含分片键 (`order_id`)，ShardingSphere 可以精确定位到具体的物理库和物理表，效率最高。
    *   如果查询条件不包含分片键（如 `selectOrdersByUserId`），ShardingSphere 会将 SQL 路由到 *所有* 配置的物理表中执行，然后合并结果。这可能导致性能问题，需要谨慎使用或通过其他方式（如ES同步、冗余字段等）优化。
    *   对于 `t_order_detail` 的单条查询，如果只用 `detail_id` (非分片键)，也会路由到所有表。如果能同时提供 `order_id` (分片键)，则可以精确定位。

3.  **Service 层 (可选，封装业务逻辑)**

    ```java
    package com.example.shardingdemo.service;

    import com.example.shardingdemo.entity.Order;
    import com.example.shardingdemo.entity.OrderDetail;
    import com.example.shardingdemo.mapper.OrderDetailMapper;
    import com.example.shardingdemo.mapper.OrderMapper;
    import org.springframework.beans.factory.annotation.Autowired;
    import org.springframework.stereotype.Service;
    import org.springframework.transaction.annotation.Transactional; // 使用 Spring 事务

    import java.math.BigDecimal;
    import java.util.List;
    import java.util.UUID;

    @Service
    public class OrderService {

        @Autowired
        private OrderMapper orderMapper;

        @Autowired
        private OrderDetailMapper orderDetailMapper;

        // 插入订单和详情，需要事务保证
        @Transactional // 开启 Spring 事务，ShardingSphere 默认支持本地事务
        public Order createOrder(Integer userId, List<String> items) {
            // 1. 创建 Order 对象
            Order order = new Order();
            order.setUserId(userId);
            order.setOrderNo(UUID.randomUUID().toString().substring(0, 16)); // 简单生成订单号
            order.setAmount(BigDecimal.valueOf(items.size() * 10.0)); // 假设每个 item 10 元

            // 2. 插入 Order，ShardingSphere 会生成 orderId 并路由
            // @Options 会将生成的 orderId 回填到 order 对象中
            orderMapper.insertOrder(order);
            System.out.println("Inserted Order ID: " + order.getOrderId()); // 获取生成的 orderId

            // 3. 插入 Order Details，使用上面获取的 orderId 作为分片键
            int quantity = 1;
            for (String itemName : items) {
                OrderDetail detail = new OrderDetail();
                detail.setOrderId(order.getOrderId()); // 关键：使用主表的 orderId
                detail.setItemName(itemName);
                detail.setQuantity(quantity++);
                orderDetailMapper.insertDetail(detail);
            }

            return order;
        }

        public Order findOrderById(Long orderId) {
            // 查询时带上分片键 orderId，会精确路由
            return orderMapper.selectOrderById(orderId);
        }

        public List<OrderDetail> findDetailsByOrderId(Long orderId) {
            // 查询时带上分片键 orderId，会精确路由
            return orderDetailMapper.selectDetailsByOrderId(orderId);
        }

        public List<Order> findOrdersByUser(Integer userId) {
            // 查询时不带分片键 orderId，会路由到所有库表
            System.out.println("Warning: Querying orders by user_id will scan all shards.");
            return orderMapper.selectOrdersByUserId(userId);
        }
    }
    ```
    *关于事务:* ShardingSphere 默认情况下，如果一个事务内的所有操作都路由到同一个物理数据库实例，它会使用数据库自身的本地事务。如果事务跨越了多个物理数据库实例（例如，一次操作修改了 `ds_0` 和 `ds_1` 中的数据），则需要配置分布式事务管理器，如 Seata (推荐) 或 XA。本例中，由于 `t_order` 和 `t_order_detail` 是绑定表，且使用 `order_id` 进行分片，`createOrder` 方法内的所有数据库操作理论上会落在同一个物理主库 (`ds_0_master` 或 `ds_1_master`)，因此 Spring 的 `@Transactional` 结合 ShardingSphere 的默认行为即可保证事务性。

4.  **Controller 层 (用于测试)**

    ```java
    package com.example.shardingdemo.controller;

    import com.example.shardingdemo.entity.Order;
    import com.example.shardingdemo.entity.OrderDetail;
    import com.example.shardingdemo.service.OrderService;
    import org.springframework.beans.factory.annotation.Autowired;
    import org.springframework.web.bind.annotation.*;

    import java.util.Arrays;
    import java.util.List;
    import java.util.Random;

    @RestController
    @RequestMapping("/orders")
    public class OrderController {

        @Autowired
        private OrderService orderService;

        private final Random random = new Random();

        @PostMapping("/create")
        public Order createOrder() {
            // 随机生成 userId 和 items 用于测试
            Integer userId = random.nextInt(1000);
            List<String> items = Arrays.asList("ItemA-" + random.nextInt(100), "ItemB-" + random.nextInt(100));
            return orderService.createOrder(userId, items);
        }

        @GetMapping("/{orderId}")
        public Order getOrderById(@PathVariable Long orderId) {
            return orderService.findOrderById(orderId);
        }

        @GetMapping("/{orderId}/details")
        public List<OrderDetail> getOrderDetails(@PathVariable Long orderId) {
            return orderService.findDetailsByOrderId(orderId);
        }

        @GetMapping("/user/{userId}")
        public List<Order> getOrdersByUserId(@PathVariable Integer userId) {
            return orderService.findOrdersByUser(userId);
        }
    }
    ```

5.  **主应用类 (Main Application)**

    ```java
    package com.example.shardingdemo;
    
    import org.mybatis.spring.annotation.MapperScan;
    import org.springframework.boot.SpringApplication;
    import org.springframework.boot.autoconfigure.SpringBootApplication;
    import org.springframework.transaction.annotation.EnableTransactionManagement;
    
    @SpringBootApplication
    @MapperScan("com.example.shardingdemo.mapper") // 扫描 Mapper 接口
    @EnableTransactionManagement // 启用注解式事务管理
    public class ShardingDemoApplication {
    
        public static void main(String[] args) {
            SpringApplication.run(ShardingDemoApplication.class, args);
        }
    }
    ```

## 第五步：运行与测试**

1.  确保你的 4 个 MySQL 数据库实例（或 4 个 database）已按要求创建好表结构，并且正在运行。
2.  修改 `application.yml` 中的数据库连接信息（URL, username, password）以匹配你的环境。
3.  运行 Spring Boot 应用 `ShardingDemoApplication`。
4.  使用 Postman 或 curl 等工具调用 Controller 接口：
    *   **创建订单:** `POST http://localhost:8080/orders/create`
        *   观察控制台日志（因为配置了 `sql-show: true` 和 ShardingSphere 的 INFO 日志）。你会看到类似以下的日志，显示 ShardingSphere 解析后的 SQL 和实际执行的 SQL（包括路由到的物理库和物理表）：
            ```
            ShardingSphere-SQL - Logic SQL: INSERT INTO t_order (user_id, order_no, amount) VALUES (?, ?, ?)
            ShardingSphere-SQL - Actual SQL::ds_1 ::: INSERT INTO t_order_0 (user_id, order_no, amount, order_id) VALUES (?, ?, ?, ?) ::: [ ..., ..., ..., generated_order_id]
            ShardingSphere-SQL - Logic SQL: INSERT INTO t_order_detail (order_id, item_name, quantity) VALUES (?, ?, ?)
            ShardingSphere-SQL - Actual SQL::ds_1 ::: INSERT INTO t_order_detail_0 (order_id, item_name, quantity) VALUES (?, ?, ?) ::: [generated_order_id, ..., ...]
            ShardingSphere-SQL - Actual SQL::ds_1 ::: INSERT INTO t_order_detail_0 (order_id, item_name, quantity) VALUES (?, ?, ?) ::: [generated_order_id, ..., ...]
            ```
            *注意:* 上面的 `ds_1` 和 `t_order_0`/`t_order_detail_0` 是基于生成的 `order_id` 模 2 的结果。多次调用 `create` 会看到数据可能写入 `ds_0` 或 `ds_1`，以及 `_0` 或 `_1` 表。
        *   记录返回的 `orderId`。
    *   **根据 ID 查询订单:** `GET http://localhost:8080/orders/{orderId}` (替换 `{orderId}` 为上一步记录的 ID)
        *   观察日志。如果是读操作，ShardingSphere 会优先路由到对应的从库（例如 `ds_1_slave` 的 `t_order_0`）。如果从库不可用或配置了强制主库查询，则会路由到主库。
        *   日志示例（查询）：
            ```
            ShardingSphere-SQL - Logic SQL: SELECT * FROM t_order WHERE order_id = ?
            ShardingSphere-SQL - Actual SQL::ds_1_slave ::: SELECT * FROM t_order_0 WHERE order_id = ? ::: [orderId]
            ```
    *   **根据 ID 查询订单详情:** `GET http://localhost:8080/orders/{orderId}/details`
        *   同样会根据 `orderId` 精确路由到对应的从库和物理表。
    *   **根据用户 ID 查询订单:** `GET http://localhost:8080/orders/user/{userId}`
        *   观察日志，你会看到 SQL 被发送到 *所有* 读数据源的 *所有* `t_order` 物理表（`ds_0_slave.t_order_0`, `ds_0_slave.t_order_1`, `ds_1_slave.t_order_0`, `ds_1_slave.t_order_1`），然后 ShardingSphere 合并结果。

5.  **验证数据:** 直接连接到你的物理数据库 `ds_0` 和 `ds_1`，检查 `t_order_0`, `t_order_1`, `t_order_detail_0`, `t_order_detail_1` 表，确认数据是否按照 `order_id % 2` 的规则分散存储。

**总结与关键点:**

1.  **透明性:** ShardingSphere 的核心优势在于对应用层透明。你的业务代码（Mapper, Service）操作的是逻辑表 (`t_order`, `t_order_detail`)，无需关心底层如何分片和路由。
2.  **配置驱动:** 绝大部分行为（数据源、分片规则、读写分离、主键生成）都是通过配置文件 (`application.yml`) 定义的。
3.  **分片键:** 选择合适的分片键 (`sharding-column`) 至关重要。它直接影响数据分布的均匀性和查询性能。查询时带上分片键效率最高。
4.  **绑定表:** 对于需要JOIN或事务一致性的关联表，务必配置为绑定表，并使用相同的分片键和策略，确保它们落在同一物理分片。
5.  **读写分离:** 能有效分摊读压力，但要注意主从延迟可能导致的数据不一致问题（读取到旧数据）。ShardingSphere 也提供强制主库路由的 Hint 方式。
6.  **分布式主键:** ShardingSphere 提供了多种分布式 ID 生成策略（Snowflake, UUID 等），解决了分片环境下的主键唯一性问题。
7.  **非分片键查询:** 尽量避免或优化不带分片键的查询，因为它们会扫描所有分片，可能成为性能瓶颈。
8.  **分布式事务:** 跨库事务需要引入 Seata 等分布式事务解决方案，配置相对复杂一些。
9.  **运维:** 分库分表增加了数据库运维的复杂度（更多的实例、备份、监控、扩容等）。

这个示例提供了一个从理论到可执行代码的完整流程。你可以基于此进行修改和扩展，以适应更复杂的业务场景。记住，仔细规划分片策略和理解其对查询的影响是成功的关键。